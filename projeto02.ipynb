{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEoVQfjUWh6d"
   },
   "source": [
    "# Projeto 2 - Transfer Learning\n",
    "Matheus Arataque Uema - 10276949\n",
    "\n",
    "Dhyogo Nunes Costa - 13096109\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Este projeto envolve usar a rede MobileNetV2, treinada com a base Imagenet e adapta--la para reconhecer dados da base \"cats and dogs\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECy_vqnobz1E"
   },
   "source": [
    "##  Etapa 1 - Base de dados\n",
    "Será utilizada a base \"cats and dogs\" , disponível em: https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip. Observe que o dataset já vem dividido em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL46PX8xcJB4"
   },
   "outputs": [],
   "source": [
    "train_dir = 'cats_and_dogs_filtered/cats_and_dogs_filtered/train'\n",
    "validation_dir = 'cats_and_dogs_filtered/cats_and_dogs_filtered/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_SYKXrAcO1g"
   },
   "source": [
    "## Etapa 2 - Redimensionamento\n",
    "Os dados serão redimensionados para o tamanho 160x160, utilizando batches de tamanho 32 e com seus valores escalados para o intervalo 0 e 1.\n",
    "Para simplificar esse processo, a classe `tf.keras.preprocessing.image.ImageDataGenerator` (com parâmetro rescale), e seu `método flow_from_directory` (com parâmetros `validation_dir, target_size, batch_size e class_mode`) serão utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFPva_tJceZi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Configuração do ImageDataGenerator para reescalonar as imagens\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "validation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Carregar as imagens a partir do diretório com redimensionamento e batch size definidos\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(160, 160),  # Redimensiona as imagens para 160x160\n",
    "    batch_size=32,           # Define o tamanho do batch como 32\n",
    "    class_mode='binary'      # Configura a classificação binária para gatos e cachorros\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(160, 160),  # Redimensiona as imagens para 160x160\n",
    "    batch_size=32,           # Define o tamanho do batch como 32\n",
    "    class_mode='binary'      # Configura a classificação binária para gatos e cachorros\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QW45IKt5dCXI"
   },
   "source": [
    "## Etapa 3 - Arquitetura da rede MobileNetV2\n",
    "A MobileNetV2 foi arquitetada visando leveza e eficiência. Para isso, ela minimiza o número de operações e parâmetros através de convoluções de profundidade separável e blocos invertidos residuais. Sua arquitetura pode ser definida da seguinte forma:\n",
    "\n",
    "**Primeira camada de convolução**: possui 32 filtros e stride de 2, seguida de uma camada de normalização Batch Normalization e ativação ReLU6.\n",
    "\n",
    "**Blocos invertidos residuais**: consistem em uma convolução 1x1 para expansão, uma consolução depthwise separável (3x3 com stride de 1 ou 2), uma convolução 1x1 para compressão, resíduo entre entrada e saída e a maioria utiliza ReLU6 como ativação.\n",
    "\n",
    "**Blocos de Expansão e Projeção**: possui uma fase de expansão - aumentando a representação dimensional - onde o número de filtros aumenta e uma de projeção - reduzindo a redundância - onde o número de filtros reduz.\n",
    "\n",
    "**Bloco Final de Convolução**: camada de convolução 1x1 com 1280 filtros.\n",
    "\n",
    "**Pooling Global**:  reduz a dimensão espacial para 1x1\n",
    "\n",
    "**Camada de Saída**: camada totalmente conectada que utiliza softmax para classificação com múltiplas classes e sigmoid para classificação binária\n",
    "\n",
    "Essa arquitetura reduz o custo computacional através das convoluções empregadas. Além disso, como a maioria das camadas é configurável com fatores de `width multiplier` e `resolution multiplier`, são permitidos ajustes no tamanho da rede e na resolução da entrada, otimizando seu uso. Por conta disso, a MobileNetV2 é altamente precisa para tarefas de visão, como classificação de imagens e detecção de objetos.\n",
    "\n",
    "Será utilizado o modelo MobileNetV2 com os pesos do ImageNet e sem as camadas totalmente conectadas. Seus pesos serão congelados, o que pode ser verificado no código abaixo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cHz5oFKWfDA"
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "# Carregar o modelo MobileNetV2 com pesos do ImageNet e sem as camadas totalmente conectadas\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))\n",
    "\n",
    "# Congelar os pesos do modelo\n",
    "base_model.trainable = False\n",
    "\n",
    "# Verificar a estrutura do modelo e confirmar que as camadas estão congeladas\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hTk9iwT-WhEx"
   },
   "source": [
    "As camadas da base de dados serão adicionadas através de uma camada totalmente conectada. Para fins de simplificação, uma camada `GlobalAveragePooling2D` será utilizada no treino, o qual utilizará como métrica a acurácia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HK9_OKE7iB1_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Adicionar novas camadas no topo do modelo\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Reduz a dimensão espacial\n",
    "x = Dense(1, activation='sigmoid')(x)  # Camada de saída para classificação binária\n",
    "\n",
    "# Criar o modelo final\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXft__m-i29y"
   },
   "source": [
    "## Etapa 4 - Validação\n",
    "\n",
    "Serão utilizadas três imagens de gatos e três imagens de cachorros para validação do modelo criado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EX3uVsFAi7xT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Função para pré-processar uma imagem e fazer a previsão\n",
    "def preprocess_and_predict(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(160, 160))  # Carregar e redimensionar a imagem\n",
    "    img_array = image.img_to_array(img) / 255.0             # Converter para array e escalar\n",
    "    img_array = np.expand_dims(img_array, axis=0)           # Expandir a dimensão para batch\n",
    "    prediction = model.predict(img_array)                   # Fazer a previsão\n",
    "    return prediction[0][0]                                 # Retorna a previsão\n",
    "\n",
    "# Caminhos para as imagens de gatos e cachorros\n",
    "image_paths = [\n",
    "    'path/to/cat1.jpg',\n",
    "    'path/to/cat2.jpg',\n",
    "    'path/to/cat3.jpg',\n",
    "    'path/to/dog1.jpg',\n",
    "    'path/to/dog2.jpg',\n",
    "    'path/to/dog3.jpg'\n",
    "]\n",
    "\n",
    "# Realizar a previsão e exibir o resultado\n",
    "for img_path in image_paths:\n",
    "    pred = preprocess_and_predict(img_path, model)\n",
    "    label = \"Dog\" if pred > 0.5 else \"Cat\"  # Limite de 0.5 para classificação binária\n",
    "    print(f\"Image: {img_path} - Predicted Label: {label} - Confidence: {pred}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```1/1 [==============================] - 1s 833ms/step\n",
    "Image: cat1.jpg - Predicted Label: Cat - Confidence: 0.000742390810046345\n",
    "1/1 [==============================] - 0s 34ms/step\n",
    "Image: cat2.jpg - Predicted Label: Cat - Confidence: 0.0006298071821220219\n",
    "1/1 [==============================] - 0s 34ms/step\n",
    "Image: cat3.jpg - Predicted Label: Dog - Confidence: 0.7990727424621582\n",
    "1/1 [==============================] - 0s 34ms/step\n",
    "Image: dog1.jpg - Predicted Label: Dog - Confidence: 0.8726528882980347\n",
    "1/1 [==============================] - 0s 34ms/step\n",
    "Image: dog2.jpg - Predicted Label: Dog - Confidence: 0.808917760848999\n",
    "1/1 [==============================] - 0s 34ms/step\n",
    "Image: dog3.jpg - Predicted Label: Dog - Confidence: 0.9711649417877197```\n",
    "\n",
    "Foram testados para cada animal, gato e cachorro, um real, um gerado por IA e um em estilo desenhado.\n",
    " As imagens reais foram corretamente identificadas.\n",
    " O mesmo pôde ser observado para as imagens geradas em IA. \n",
    " No entanto, para os estilos desenhados, o modelo gerado errou na identificação da imagem de gato utilizado."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
